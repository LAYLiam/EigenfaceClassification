{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenfaces (Linear Algebra Face Classification)\n",
    "> All code is written in Python 3.12.1. Code may not perform as expected otherwise.\n",
    "\n",
    "The dependancies of this notebook include: **numpy**, **mathplotlib**, **PIL**, **os**, and **pathlib**. \\\n",
    "This notebook seeks to implement methods described in the Turk and Pentland 1991 paper \"Eigenfaces for Recognition\".\\\n",
    "See: [\"Eigenfaces for Recognition\"](https://sites.cs.ucsb.edu/~mturk/Papers/mturk-CVPR91.pdf) by Matthew A. Turk and Alex P. Pentland at MIT.\\\n",
    "Additional resources: \n",
    "[[2]](https://doi.org/10.1016/j.protcy.2012.02.023, \"A Face Recognition System Based on Eigenfaces Method by M.üge Çarıkçı & Figen Özen\"), \n",
    "[[3]](https://www.ijstr.org/final-print/mar2020/Face-Recognition-By-Using-Eigen-Face-Method.pdf, \"Face Recognition By Using Eigen Face Method\n",
    "by V. Jalaja & G.S.G.N. Anjaneyulu\"). \\\n",
    "It is significant to note that Turk and Pentland atrribute the motivation of using 'eigenfaces' to L. Sirovich and M. Kirby [[see]](https://opg.optica.org/josaa/fulltext.cfm?uri=josaa-4-3-519&id=2689, \"Low-dimensional procedure for the characterization of human faces by L. Sirovich and M. Kirby\"). \n",
    "\n",
    "> 1. Access and convert a set of test images into grayscale.\n",
    "> 2. Convert the image from *N x N* (where *N* represents the h & w pixel magnitude) into a column vector with *N x 1* dimensionality.\n",
    "> 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt  \n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0. Vectorize Images and Load Into N x M Matrix\n",
    "Every digital image can be defined as a set of pixels on a $N_a \\times N_b$ grid (assuming single channel, grayscale not RGB). \\\n",
    "For the images which will be loaded as the training set, they have been pre-processed to be square such that $N_a = N_b = N$. \\\n",
    "As such each image is an $N \\times N$ image ($N^2$ pixels), where $N = 128$ pixels.\\\n",
    "Digital images can be represented as a set of vectors by flattening the images to be of $N \\times 1$ dimensionality.\n",
    "\n",
    "Load all training images into a matrix, let the quantity of all training examples be $M$. \\\n",
    "Each image can be flattened, and added to a matrix horizontially to make a 'face space' (all the faces in a matrix).\\\n",
    "This new matrix, which we call $A$ will have the dimensionality $N^2 \\times M$. \\\n",
    "We represent a single image, translated into a vector as the mathematical symbol gamma ($\\Gamma_i$). \\\n",
    "The new matrix $A_0$ can be represented as the following: $A_o = [ \\Gamma_1, \\Gamma_2, ..., \\Gamma_M]$.\n",
    "\n",
    "We can use OpenCV2 (cv2) to load each of the images into numpy vectors, collated to make matrix $A_o$. \\\n",
    "OpenCV's imread takes a second parameter, which converts images into grayscale on load if provided with a zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your path here relative to this file\n",
    "# Note: images need to be pre-processed to be of 128 x 128 pixel dimensionality.\n",
    "PATH = str(Path.cwd()) + \"\\\\faces\"\n",
    "IMAGE_NAMES = os.listdir(PATH)\n",
    "M = len(IMAGE_NAMES)\n",
    "N = 128 \n",
    "\n",
    "# A_0 is the matrix containing all images, represented by column vectors\n",
    "A_0 = []\n",
    "for name in IMAGE_NAMES:\n",
    "    image = cv2.imread(PATH + \"\\\\\" + name, 0)\n",
    "    phi = np.asarray(image).reshape(1, N * N)[0]\n",
    "    A_0.append(phi)\n",
    "A_0 = np.array(A_0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Generate Mean/Average Face\n",
    "Now lets talk about what this paper posits as a solution to recognizing faces within a frame (we will get to classification later).\\\n",
    "Instead of performing feature analysis specific regions of faces (i.e., recongition by distance between eyes and nose), \\\n",
    "Turk and Pentland propose the generation of a **mean** or **average** face, alongside a set of characteristics which deviate from \\\n",
    "the mean face (which they named **eigenfaces**), from which faces can be approximated or regenerated by a linear combination \\\n",
    "of eigenfaces with the average face.\n",
    "\n",
    "So what? When implemented well, with enough training data, the model should be able to regenerate any image as a linear combination of eigenfaces \\\n",
    "(even if not a face). When regenerating images, weights are also calculated which are applied to each eigenface. Calculating the euclidian distances \\\n",
    "between a regenerated face, and a known face, can help us perform person recognition...however, we are getting ahead of ourselves here.\n",
    "\n",
    "What is important to note here, is that we are interested in a **mean** face. \\\n",
    "We will figure out how to generate eigenfaces in the next section.\n",
    "\n",
    "The mean face takes each column vector $\\Gamma_i$ and averages each of its rows across the total sample size $M$. \\\n",
    "The symbol we use to represent the mean face is the mathematical symbol psi ($\\psi$), and the average face is given by: \\\n",
    "$\\psi = \\frac{1}{M} \\sum_{n = 1}^M \\Gamma_i$, since we already have $A_o$, we can take the averages of the columns.\\\n",
    "Here is an example of what this looks like, just with a few Mark Zuckerberg images:\n",
    "> \n",
    "> [<img src=\"source/average-face-example-zucc.jpg\" width=\"550\"/>](source/average-face-example-zucc.jpg)\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean face ψ\n",
    "psi = A_0.mean(axis=1).reshape(N * N, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:**\n",
    "We can have a look at what the average face looks like. \\\n",
    "We'll first print out the matrix to see the values of each pixel, which represent grayscale intensity,\\\n",
    "Then we'll use mathplotlib to translate the matrix into an image. \n",
    "\n",
    "_You can also add print(psi) to see the individual pixel values which matplotlib is plotting._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "plt.title('Mean face (psi, ψ) visualized'),plt.imshow(psi.reshape(N, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Normalize Face Space\n",
    "Remember how we discussed regenerating faces via a linear combination of 'eigenfaces' with the mean face? \\\n",
    "We discussed how the 'eigenfaces' are related to discrepencies between faces. To progress towards this, \\\n",
    "we'll first need to grab the unique features of each image by subtracting the mean face from each training image. \\\n",
    "In other words, we'll remove the normalness from each image to be left with a unique ghost-like image. \\\n",
    "After we remove the normalness, we will have normalized the 'face space'.\n",
    "\n",
    "We have previously defined $A_0$ as all the images in the training set, represented as column vectors, contained in a matrix.\\\n",
    "We have also defined psi as the mean face. Numpy allows us to perform element-wise arithmetic across two matricies,  \n",
    "even if they have different dimensionalities, only if one is shared and the other is a multiple of the other. \\\n",
    "This is called __broadcasting__.\n",
    "\n",
    "> Here's an example: \\\n",
    "> Let $A$ be a matrix of $1 \\times 5$ dimensionality, and $B$ be a matrix of $12 \\times 5$ dimensionality. \\\n",
    "> With Numpy, without making any changes to $A$ or $B$, we can perform the matrix operation $A + B$. \\\n",
    "> Numpy will take the matrix $A$ and duplicate it $12$ times horizontally to make it become a $12 \\times 5$ matrix.\\\n",
    "> After broadcasting matrix $A$ to match the dimensionality of $B$, Numpy will perform element-wise addition.\n",
    "\n",
    "This is incredibly useful in our case, as we can take the stored faces in $A_o$ of $N^2 \\times M$ dimensionality, \\\n",
    "and exploit Numpy's broadcasting feature to subtract the mean face, with $N^2 \\times 1$ dimensionality, from each \\\n",
    "image column vector.  \n",
    "\n",
    "The set of all normalized face images is defined as $A = [\\phi_1, \\phi_2, ..., \\phi_M]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A_0 - psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # In progress from this point on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Principle Component Analysis\n",
    "Here we enter the next stage of calculating our 'eigenfaces'. Here we'll perform something called \\\n",
    "Principle Component Analysis (PCA) or Karhunen-Loeve expansion (some resources: [[1]](https://www.geeksforgeeks.org/principal-component-analysis-pca/ \"Geek for Geeks PCA\"), [[2]])\n",
    "\n",
    "Generally speaking, there are three key steps to PCA:  \n",
    "1. Standardize the testing data.\n",
    "2. Generate a covariance matrix.\n",
    "3. Compute eigenvalues/eigenvectors of covariance matrix to identify the principle components.  \n",
    "\n",
    "We'll skip to calculating the covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2.1. Covariance Matrix\n",
    "To generate the covariance matrix, we perform matrix multiplication on itself transposed.\n",
    "i.e., $C = A A^T$.  \n",
    "What you'll notice, however, is that we are performing the mutliplication for dimensionalities $N^2 \\times M$ and $M \\times N^2$\\\n",
    "which results in a dimensionality of $N^2 \\times N^2$, which if we want to perform any more matrix manipulation will be too computationally large! \n",
    "\n",
    "Thankfully, we can also perform matrix manipulations to achieve desired results with a \n",
    "lower dimensionality matrix defined as: $L = A^T A$, which is a matrix of $M \\times M$ dimensionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.dot(A.T, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** You can test for your self to compare the computational resource\\\n",
    "required to calculate covariance-matrix $C$. Run the following code and see the\\\n",
    "time it takes for the notebook.\n",
    "\n",
    "Since we are performing a calculation that results in a $N^2 \\times N^2$ dimensionality  matrix,  \n",
    "we are performing calculations for $N^4$ elements ($N^4 = 128^4 = 16,384$)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "C = np.dot(A, A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Computing Eigenvalues/Eigenvectors\n",
    "text about deriving eigenvalues and eigenvectors from covariance matrix,\n",
    "and pulling first k eigenvectors from the eigenvalue pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top eigenfaces used\n",
    "M_prime = 50\n",
    "lambda_, u = np.linalg.eig(L)\n",
    "\n",
    "# Sort eigenvectors by eigenvalues largest to smallest, and select first M'.\n",
    "eigenpair = sorted([(lambda_[i], u[i]) for i in range(M)])[:M_prime:-1]\n",
    "u = np.array([eigenpair[i][1] for i in range(M_prime)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "u_proj = np.dot(u, A.T)\n",
    "display_eigenfaces = plt.figure(figsize=(5, 15))\n",
    "for i in range(M_prime):\n",
    "    display_eigenfaces.add_subplot(10, 5, i + 1),plt.title(i),plt.imshow(u_proj[i].reshape(N, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Classification\n",
    "Required to project new image onto face-space, one eigenface at a time.  \n",
    "Per eigenface, formula defined as: $w_k = u_k^T (\\Gamma - \\psi)$.  \n",
    "For completion in one operation: $W = u^T (\\Gamma - \\psi)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16384, 1)\n"
     ]
    }
   ],
   "source": [
    "def get_weights(image):\n",
    "    global M_prime, u, psi\n",
    "\n",
    "    W = []\n",
    "    for k in range(M_prime):\n",
    "        normalized_image = image - psi \n",
    "        W.append(np.dot(u[k].reshape(M, 1).T, normalized_image.T).T)\n",
    "    return np.array(W)\n",
    "\n",
    "def regenerate_image(image):\n",
    "    global psi\n",
    "    W = get_weights(image)\n",
    "    print(W.shape)\n",
    "\n",
    "print(get_weights(A_0[3])[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
